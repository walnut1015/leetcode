###2018-06-19
###论文：Answering Natural Language Questions by Subgraph Matching over Knowledge Graphs
---
+ 假定的前提：存在KB中所有的节点和边的 mention dictionary
+ **relation-first**方法的步骤：
	+ 1.对问句进行依存句法分析
	+ 2.对关系的mention dictionary建倒排索引，以单词为键，value为包含该键的关系集合；对一个问句中的每一个单词，依据倒排索引选出包含改词的候选关系
	+ 3.在句子中以某个单词wi为树根，如果wi存在一个和某关系匹配的子树，则找到了候选的关系
	+ 4.与wi单词有如下依存关系的，分别被认为是关系的arg1,arg2.
		+ (1) subject-like relations: subj, nsubj, nsubjpass, csubj,
csubjpass, xsubj, poss, partmod;
		+ (2) object-like relations: obj, pobj, dobj, iobj
	+ 5.如果4不成立，则用 
		+  Rule 1: Extend the embedding t with some light
words, such as prepositions, auxiliaries.
		+ Rule 2: If the root node of t has subject/object-like
relations with its parent node in Y , add the parent
node to arg1.
  		+ Rule 3: If the parent of the root node of t has subjectlike relations with its neighbors, add the child to arg1.
  		+ Rule 4: If one of arg1/arg2 is empty, add the nearest
wh-word or the first noun phrase in t to arg1/arg2
	+ 6.基于词典的实体链接，计算置信度；关系也有一个置信度；两种置信度用于组合计算问句中提取的semantic graph和KB中的子图的匹配度
	+ 7.子图匹配使用枚举所有候选边和节点的组合的方法，加上
		+ (1) neighborhood-based pruning
		+ (2) 没看懂
+ **node-first**方法的步骤：
	+ 1.
###2018-11-19
###论文：Addressing ontology-based question answering with collections of user queries
- 重新阅读QACID  --->**非英语的问答系统才是较好的借鉴**
- 该问答系统所基于的知识库规模太小了。
	- 问题库被自动聚类为50+种类别（聚类方法未知）每一个类别的问题对应同一种SPARQL模板，模板中有Class（需要被实例化为具体的实例），属性是固定的。所以这50+类别只能对应到规模很小的知识库。
	- 实体识别标注 方法未知
- 蕴含引擎：推出用户问题和用户问题模板库中的问题之间的蕴含关系 
	- 词汇蕴含推理
		- 计算句子词汇相似度
		- 疑问词是否相似
	-  语义相似度
		-  是否包含同样类型和数量的实体
		-  是否有相同含义的属性称谓
	- 各个相似度系数相加，高于阈值（阈值凭经验取）则属于某类问题，低于阈值则不属于某类问题。因为数据集不够，所以没有使用机器学习，各种相似度不赋权重。
	
	- 基于本体的语义推理
- 文献：
	- (Chang, He, & Zhang, 2005) 
	-  repositories of on-line FAQ centered on specific domains could be used for this issue. 
	-  文本蕴涵的定义：Dagan and Glickman (2004)
###2018-11-19 参考各论文中的问题分类方法
###论文：基于改进贝叶斯模型的问题分类
-  词袋模型即无视句子中词语的顺序关系对句子意思的影响
	-  P(ci, w1,w2,...,wn)=P(c1,w1)·P(c2,w1)·····P(cn,w1)
	-  特征加权重，权重为某个特征在该类别中出现的特异度
###论文：杜泽宇——基于中文知识图谱的电商领域问答算法设计与系统实现--
- 建立了关键词词典，根据问题中这些词典词汇是否出现，将问题转化为0,1组成的向量。使用SVM

###论文：中文问答系统中问题分类及答案候选句抽取的研究--2006
- 文本分类和问题分类很不一样，tf-idf权重不适合于问题分类
- 问句进行句法分析，得到依存关系，提取句子主干（主谓宾），句子的依存词对和依存关系作为特征；疑问词也作为特征；实体类别也作为特征。使用SVM分类器，特征的权重使用和《基于改进贝叶斯模型的问题分类》中类似的权重计算方法

###2018-11-19 参考各论文中的问题理解方法
###论文 more acurate question answering on freebase（2015）
- 实体链接：
	- 将句子中的名称组成的名词短语作为可能的实体，匹配上候选的模板
		- 实体链接方法：使用既有的别名词典CrossWiksi，其中包含了词语应当被链接到某个实体的概率,选择emax；对于在CrossWikis中不包含的Freebase实体，如果实体和问句中的名词短语相同，则通计算其在FACC1中与emax的相对提及频率，得到的概率作为其可能匹配上问题中词汇的概率 ===> 中文领域缺乏这样的词典和标注好了的语料库，也对该方法的合理性表示怀疑。
	- 对于匹配上的模板中其它关系，计算问题中的词和这些关系称谓的相似度。
		- 词汇相同匹配度
		- 词汇变体匹配度
			- 将问题中的词汇转换成各自的变体，看关系称谓中与变体多少对是相同的词
		- 同义词匹配度
			- 1000亿词汇的语料库，用word2vec得到300维的词向量，取cosin相似度大于0.4(经验观察值)的词作为近义词。
		- 上下文匹配度：
			- 预计算出知识库中每一个关系的带权指标词，若句中出现了某一个关系的指标词，则将所有对应的指标词汇权重相加作为该关系对应的上下文匹配度 
				- 指标词的计算：远程监督
				- 断点：关系抽取
			- 指标词汇的权重计算：某个关系对应的top-1000词汇的tf.idf总和为sum,各个词汇的tf.idf占sum的比值。(**词汇和关系称谓的相似度不作为考量范围么？**)
			- 如果在语料中一个指示词可以指示多个关系，则通过判断用户问题的答案类型来剔除
	- 个人看法：如果是	

###2018-11-27
- 目前对最前沿的技术了解太少了，神经网络，神经模型，迁移学习，还有《开放知识图谱》中的过往文章，都应该好好读一读。
- 争取用3天，神经网络入个门。
- 读50篇KBQA相关的文章
###2018-11-29 断点————关系抽取
- 远程监督：论文《Distant supervision for relation extraction without labeled data》 2009，ACL（自然语言处理的顶会）
	- Distant Supervision 通过将知识库与非结构化文本对齐来自动构建大量训练数据，减少模型对人工标注数据的依赖，增强模型跨领域适应能力。
	- 假定句子中若包含两个实体，两个实体在KB中由属性r相连接，则句子中也会包含属性r。因此句子只要识别出了

###2018/12/06
- 计划
	- 阅读《揭开知识库问答KB-QA的面纱》系列
	- 了解肖阳华的 知识工场 实验室的成果。实体识别，关系抽取，提供的标注数据
	- 种子，模式
- 阅读：《揭开知识库问答KB-QA的面纱-2-语义解析》
	- semantic parsing:将问题转化为知识库能看懂的逻辑形式。
		- 逻辑形式，如**Lambda-DCS**，可以表示实体、二元实体关系组、join,intersection,aggregate操作等。
			- ???为什么我会需要理解逻辑形式？感觉只要把问题转化为SPARQL就够了啊
		- 语义解析的过程可以看做是自底向上构造**语法树**的过程，分为两个步骤：
			- 断点：语法树是什么？自然语言处理教程 **√**
			- 断点：短语和命名实体识别是否有一些关系？
				 
			- 词汇映射： 
			
---
###2018/12/11
- 粗略翻阅了《自然语言处理技术基础》
	- 重写规则和转移网络可以用来描述语法
	- 利用重写规则，我们可以用自顶向下、自底向上的方法来确定句子的合理性以及句子的语法成分。			
	- 语法和语义分析中都可能出现歧义，有的歧义是需要依靠世界知识来解决的。
		- 可以将词语的每一种意思定义为义元，不同词语的义元之间有上下位、相反、同义等关系
		- 原型————列出每一类事物的典型实例，而不是用统一的方式来描述这类事物的每个个体
	- 语义分析
		- 句子可以用逻辑表达式来表示。lambda演算便是其中的一种。利用lambda表达式可以结合语法分析结果得出句子的语义表示
		- 在限定领域，利用语义类别范畴，也可以不依靠语法分析，直接得出句子的语义表示
		- 句子中的某些有带修饰词的NP如： every dog, a dog, 虽然在句法分析上是一个整体，但是在逻辑表示却有不同。它们表示了一种存在量词
		- 但是上述方法均无法克服句子中有俚语的情况，因为俚语“顾左右而言其他”。
#####阅读《KBQA-1》
- 做KBQA的三类传统主流方法（主要为2013-2014年）
	- 语义解析，将问题转换为逻辑表达式，并在知识库中进行查询		
	- 信息抽取，
	- 向量建模，
- 15年之后开始有大量深度学习的方法，通过深度学习对传统方法进行提升
	
- KBQA的评价指标：召回率，精确率，F1值，BLUE，Perplexity 
- 问答数据集：WebQuestion
###2018/12/15 阅读《KBQA-2》论文： Semantic Parsing on Freebase from Question-Answer Pairs 2013 EMNLP
- 根据POS、命名实体识别、以及一些既定的构词规则，将词语识别为可能的实体，并映射到对应的实体上。对于关系则进一步执行对齐操作。ClueWeb上

---
###2018/12/17 阅读《KBQA-3》论文： Information Extraction over Structured Data:Question Answering with Freebase 2014 **ACL** （用信息抽取的方法来进行KB-QA）
- 假定：从有关的实体出发，N跳关系内形成的子图中一定包含了答案
- KBQA面临的两个大问题：
	- 问题模型：找到问题的表示形式，转化为查询并能够在KB上执行得到答案
		- 目前的解决方案：用一种介于问题和查询之间的中间表示形式来进行桥接，如：组合范畴语法（CCG），同步上下文无关语法，逻辑生成依赖树，string kernels等
	- 数据挑战：	
- 断点：论文《paraphrase-driven learning for open question answering》 2013,**ACL**
	- 本文从问答对中学习得到词典，词典中学习到很多同义句及其对应的知识库表示形式，以及关系、实体指称及其对应的知识库实体
	- 数据：1800万个问答对
	- 学来的模板：
		>How big is e?  --->  population(e,?)| How r is e? ---> r(e,?)
		- 有的关系称谓并没有明显的对应关系，如：华为P8有哪些芯片？
		- 模板之间会不会有包含关系呢 
	-  
---
### 总结
- 我需要解决的问题中不仅仅有实体，还有描述语句字符串、数字值，即数据类型属性的值。 SUTime
- 自然语言处理方面的顶会：EMNLP，ACL,ccks(全国语义计算与知识图谱大会)
- 知识图谱和问答系统研讨会
- 当用户提问时，所设想的实体之间的联系和KB中的不一致怎么办？如：美国的航空母舰有哪些级？知识库中有这类信息，但是不够明确
- 一个生成问题集的想法：用模板组合很多的问题，放到百度知道中去问，然后每一次搜索取前10个搜索结果中的问题，人工从中挑选问题、或者根据问法组合问题。
- 需要找到合适的领域相关论坛
- 似乎卡在了“如何切分出句子中的实体”这一关。命名实体识别真的好难啊

---
### <font color="Red" size = 6>资源</font>
- SUTime
- OpenKG,包含多个知识图谱，以及知识图谱相关的工具
- 自然语言的一些好的会议：CCKS（知识图谱，中国）,EMNLP,ACL
- http://www.ccks2018.cn/?page_id=16 开放领域的中文问答任务，提供1000多个标注好的问答集，基于PKUBase (还是 PKU-Pie？)
- 统计自然语言处理----宗庆成，基于深度学习的自然语言处理----(以) 约阿夫·戈尔德贝格著

---
### 待读的论文库
- 语义解析
	-  Berant J, Chou A, Frostig R, et al. Semantic Parsing on Freebase from Question-Answer Pairs[C]//EMNLP. 2013, 2(5): 6. **-√**
	-  Cai Q, Yates A. Large-scale Semantic Parsing via Schema Matching and Lexicon Extension[C]//ACL (1). 2013: 423-433.
	-  Kwiatkowski T, Choi E, Artzi Y, et al. Scaling semantic parsers with on-the-fly ontology matching[C]//In Proceedings of EMNLP. Percy. 2013.
	-  Fader A, Zettlemoyer L, Etzioni O. Open question answering over curated and extracted knowledge bases[C]//Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014: 1156-1165.
- 信息抽取：
	- Yao X, Van Durme B. Information Extraction over Structured Data: Question Answering with Freebase[C]//ACL (1). 2014: 956-966
- 向量建模：
	-   Bordes A, Chopra S, Weston J. Question answering with subgraph embeddings[J]. arXiv preprint arXiv:1406.3676, 2014.
	-   Yang M C, Duan N, Zhou M, et al. Joint Relational Embeddings for Knowledge-based Question Answering[C]//EMNLP. 2014, 14: 645-650.
	-   Bordes A, Weston J, Usunier N. Open question answering with weakly supervised embedding models[C]//Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer Berlin Heidelberg, 2014: 165-180.
- 深度学习
	-   使用卷积神经网络对向量建模方法进行提升： 

		-   Dong L, Wei F, Zhou M, et al. Question Answering over Freebase with Multi-Column Convolutional Neural Networks[C]//ACL (1). 2015: 260-269. 

	-   使用卷积神经网络对语义解析方法进行提升： 

		-   Yih S W, Chang M W, He X, et al. Semantic parsing via staged query graph generation: Question answering with knowledge base[J]. 2015. 

		-   注：该 paper 来自微软，是 ACL 2015 年的 Outstanding paper，也是目前 KB-QA 效果最好的 paper 之一。

	-   使用长短时记忆网络（Long Short-Term Memory，LSTM），卷积神经网络（Convolutional Neural Networks，CNNs）进行实体关系分类： 

		-   Xu Y, Mou L, Li G, et al. Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths[C]//EMNLP. 2015: 1785-1794. 

		-   Zeng D, Liu K, Lai S, et al. Relation Classification via Convolutional Deep Neural Network[C]//COLING. 2014: 2335-2344.（Best paper） 

		-   Zeng D, Liu K, Chen Y, et al. Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks[C]//EMNLP. 2015: 1753-1762. 

		-   使用记忆网络（Memory Networks），注意力机制（Attention Mechanism）进行 KB-QA： 

		-   Bordes A, Usunier N, Chopra S, et al. Large-scale simple question answering with memory networks[J]. arXiv preprint arXiv:1506.02075, 2015. 

		-   Zhang Y, Liu K, He S, et al. Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information[J]. arXiv preprint arXiv:1606.00979, 2016. 