###2018-06-19
###论文：Answering Natural Language Questions by Subgraph Matching over Knowledge Graphs
---
+ 假定的前提：存在KB中所有的节点和边的 mention dictionary
+ **relation-first**方法的步骤：
	+ 1.对问句进行依存句法分析
	+ 2.对关系的mention dictionary建倒排索引，以单词为键，value为包含该键的关系集合；对一个问句中的每一个单词，依据倒排索引选出包含改词的候选关系
	+ 3.在句子中以某个单词wi为树根，如果wi存在一个和某关系匹配的子树，则找到了候选的关系
	+ 4.与wi单词有如下依存关系的，分别被认为是关系的arg1,arg2.
		+ (1) subject-like relations: subj, nsubj, nsubjpass, csubj,
csubjpass, xsubj, poss, partmod;
		+ (2) object-like relations: obj, pobj, dobj, iobj
	+ 5.如果4不成立，则用 
		+  Rule 1: Extend the embedding t with some light
words, such as prepositions, auxiliaries.
		+ Rule 2: If the root node of t has subject/object-like
relations with its parent node in Y , add the parent
node to arg1.
  		+ Rule 3: If the parent of the root node of t has subjectlike relations with its neighbors, add the child to arg1.
  		+ Rule 4: If one of arg1/arg2 is empty, add the nearest
wh-word or the first noun phrase in t to arg1/arg2
	+ 6.基于词典的实体链接，计算置信度；关系也有一个置信度；两种置信度用于组合计算问句中提取的semantic graph和KB中的子图的匹配度
	+ 7.子图匹配使用枚举所有候选边和节点的组合的方法，加上
		+ (1) neighborhood-based pruning
		+ (2) 没看懂
+ **node-first**方法的步骤：
	+ 1.
###2018-11-19
###论文：Addressing ontology-based question answering with collections of user queries
- 重新阅读QACID  --->**非英语的问答系统才是较好的借鉴**
- 该问答系统所基于的知识库规模太小了。
	- 问题库被自动聚类为50+种类别（聚类方法未知）每一个类别的问题对应同一种SPARQL模板，模板中有Class（需要被实例化为具体的实例），属性是固定的。所以这50+类别只能对应到规模很小的知识库。
	- 实体识别标注 方法未知
- 蕴含引擎：推出用户问题和用户问题模板库中的问题之间的蕴含关系 
	- 词汇蕴含推理
		- 计算句子词汇相似度
		- 疑问词是否相似
	-  语义相似度
		-  是否包含同样类型和数量的实体
		-  是否有相同含义的属性称谓
	- 各个相似度系数相加，高于阈值（阈值凭经验取）则属于某类问题，低于阈值则不属于某类问题。因为数据集不够，所以没有使用机器学习，各种相似度不赋权重。
	
	- 基于本体的语义推理
- 文献：
	- (Chang, He, & Zhang, 2005) 
	-  repositories of on-line FAQ centered on specific domains could be used for this issue. 
	-  文本蕴涵的定义：Dagan and Glickman (2004)
###2018-11-19 参考各论文中的问题分类方法
###论文：基于改进贝叶斯模型的问题分类
-  词袋模型即无视句子中词语的顺序关系对句子意思的影响
	-  P(ci, w1,w2,...,wn)=P(c1,w1)·P(c2,w1)·····P(cn,w1)
	-  特征加权重，权重为某个特征在该类别中出现的特异度
###论文：杜泽宇——基于中文知识图谱的电商领域问答算法设计与系统实现--
- 建立了关键词词典，根据问题中这些词典词汇是否出现，将问题转化为0,1组成的向量。使用SVM

###论文：中文问答系统中问题分类及答案候选句抽取的研究--2006
- 文本分类和问题分类很不一样，tf-idf权重不适合于问题分类
- 问句进行句法分析，得到依存关系，提取句子主干（主谓宾），句子的依存词对和依存关系作为特征；疑问词也作为特征；实体类别也作为特征。使用SVM分类器，特征的权重使用和《基于改进贝叶斯模型的问题分类》中类似的权重计算方法

###2018-11-19 参考各论文中的问题理解方法
###论文 more acurate question answering on freebase（2015）
- 实体链接：
	- 将句子中的名称组成的名词短语作为可能的实体，匹配上候选的模板
		- 实体链接方法：使用既有的别名词典CrossWiksi，其中包含了词语应当被链接到某个实体的概率,选择emax；对于在CrossWikis中不包含的Freebase实体，如果实体和问句中的名词短语相同，则通计算其在FACC1中与emax的相对提及频率，得到的概率作为其可能匹配上问题中词汇的概率 ===> 中文领域缺乏这样的词典和标注好了的语料库，也对该方法的合理性表示怀疑。
	- 对于匹配上的模板中其它关系，计算问题中的词和这些关系称谓的相似度。
		- 词汇相同匹配度
		- 词汇变体匹配度
			- 将问题中的词汇转换成各自的变体，看关系称谓中与变体多少对是相同的词
		- 同义词匹配度
			- 1000亿词汇的语料库，用word2vec得到300维的词向量，取cosin相似度大于0.4(经验观察值)的词作为近义词。
		- 上下文匹配度：
			- 预计算出知识库中每一个关系的带权指标词，若句中出现了某一个关系的指标词，则将所有对应的指标词汇权重相加作为该关系对应的上下文匹配度 
				- 指标词的计算：远程监督
				- 断点：关系抽取
			- 指标词汇的权重计算：某个关系对应的top-1000词汇的tf.idf总和为sum,各个词汇的tf.idf占sum的比值。(**词汇和关系称谓的相似度不作为考量范围么？**)
			- 如果在语料中一个指示词可以指示多个关系，则通过判断用户问题的答案类型来剔除
	- 个人看法：如果是	

###2018-11-27
- 目前对最前沿的技术了解太少了，神经网络，神经模型，迁移学习，还有《开放知识图谱》中的过往文章，都应该好好读一读。
- 争取用3天，神经网络入个门。
- 读50篇KBQA相关的文章
###2018-11-29 断点————关系抽取
- 远程监督：论文《Distant supervision for relation extraction without labeled data》 2009，ACL（自然语言处理的顶会）
	- Distant Supervision 通过将知识库与非结构化文本对齐来自动构建大量训练数据，减少模型对人工标注数据的依赖，增强模型跨领域适应能力。
	- 假定句子中若包含两个实体，两个实体在KB中由属性r相连接，则句子中也会包含属性r。因此句子只要识别出了

###2018/12/06
-计划
	- 阅读《揭开知识库问答KB-QA的面纱》系列
	- 了解肖阳华的 知识工场 实验室的成果。实体识别，关系抽取，提供的标注数据
	- 种子，模式
- 阅读：《揭开知识库问答KB-QA的面纱-2-语义解析》
	- semantic parsing:将问题转化为知识库能看懂的逻辑形式。
		- 逻辑形式，如Lambda-DCS，可以表示实体、二元实体关系组、join,intersection,aggregate操作等。

### 总结
- 我需要解决的问题中不仅仅有实体，还有描述语句字符串、数字值，即数据类型属性的值。 SUTime
- 自然语言处理方面的顶会：EMNLP，ACL